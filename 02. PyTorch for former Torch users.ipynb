{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors\n",
    "\n",
    "# Autograd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn package\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/former_torchies/nn_tutorial.html#sphx-glr-beginner-former-torchies-nn-tutorial-py\n",
    "\n",
    "## Example 1: ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTConvNet(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n",
      "torch.Size([10, 1, 5, 5])\n",
      "torch.Size([10])\n",
      "torch.Size([20, 10, 5, 5])\n",
      "torch.Size([20])\n",
      "torch.Size([50, 320])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MNISTConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = self.pool1(F.relu(self.conv1(input)))\n",
    "#         print('out1', x.shape)\n",
    "        \n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "#         print('out2', x.shape)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "#         print('view out', x.shape)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "net = MNISTConvNet()\n",
    "print(net)\n",
    "\n",
    "params = list(net.parameters())\n",
    "for p in params:\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 28, 28)\n",
    "out = net(input)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 5, 5])\n",
      "torch.Size([10])\n",
      "torch.Size([20, 10, 5, 5])\n",
      "torch.Size([20])\n",
      "torch.Size([50, 320])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "for p in params:\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2193)\n"
     ]
    }
   ],
   "source": [
    "target = torch.tensor([3], dtype=torch.long)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "err = loss_fn(out, target)\n",
    "err.backward()\n",
    "\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(net.conv1.weight.grad.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8797)\n",
      "tensor(0.6236)\n"
     ]
    }
   ],
   "source": [
    "print(net.conv1.weight.data.norm())\n",
    "print(net.conv1.weight.grad.data.norm())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward and Backward Function Hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Conv2d forward\n",
      "\n",
      "input:  <class 'tuple'>\n",
      "input.shape:  1\n",
      "input[0]:  <class 'torch.Tensor'>\n",
      "output:  <class 'torch.Tensor'>\n",
      "\n",
      "input size:  torch.Size([1, 10, 12, 12])\n",
      "output size:  torch.Size([1, 20, 8, 8])\n",
      "output norm:  tensor(13.0571)\n"
     ]
    }
   ],
   "source": [
    "def printnorm(self, input, output):\n",
    "    print('Inside ' + self.__class__.__name__ + ' forward')\n",
    "    print('')\n",
    "    print('input: ', type(input))\n",
    "    print('input.shape: ', len(input))\n",
    "    print('input[0]: ', type(input[0]))\n",
    "    print('output: ', type(output))\n",
    "    print('')\n",
    "    print('input size: ', input[0].size())\n",
    "    print('output size: ', output.data.size())\n",
    "    print('output norm: ', output.data.norm())\n",
    "    \n",
    "net.conv2.register_forward_hook(printnorm)\n",
    "\n",
    "out = net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Conv2d forward\n",
      "\n",
      "input:  <class 'tuple'>\n",
      "input.shape:  1\n",
      "input[0]:  <class 'torch.Tensor'>\n",
      "output:  <class 'torch.Tensor'>\n",
      "\n",
      "input size:  torch.Size([1, 10, 12, 12])\n",
      "output size:  torch.Size([1, 20, 8, 8])\n",
      "output norm:  tensor(13.0571)\n",
      "Inside Conv2d backward\n",
      "Inside class: Conv2d\n",
      "\n",
      "grad_input:  <class 'tuple'>\n",
      "grad_input.len:  3\n",
      "grad_input[0]:  <class 'torch.Tensor'>\n",
      "grad_output:  <class 'tuple'>\n",
      "grad_output.len:  1\n",
      "grad_output[0]:  <class 'tuple'>\n",
      "\n",
      "grad_input[0] size:  torch.Size([1, 10, 12, 12])\n",
      "grad_input[1] size:  torch.Size([20, 10, 5, 5])\n",
      "grad_input[2] size:  torch.Size([20])\n",
      "grad_output size:  torch.Size([1, 20, 8, 8])\n",
      "grad_input norm:  tensor(1.00000e-02 *\n",
      "       1.5216)\n"
     ]
    }
   ],
   "source": [
    "def printgradnorm(self, grad_input, grad_output):\n",
    "    print('Inside ' + self.__class__.__name__ + ' backward')\n",
    "    print('Inside class: ' + self.__class__.__name__)\n",
    "    print('')\n",
    "    print('grad_input: ', type(grad_input))\n",
    "    print('grad_input.len: ', len(grad_input))\n",
    "    print('grad_input[0]: ', type(grad_input[0]))\n",
    "    print('grad_output: ', type(grad_output))\n",
    "    print('grad_output.len: ', len(grad_output))\n",
    "    print('grad_output[0]: ', type(grad_output))\n",
    "    print('')\n",
    "    print('grad_input[0] size: ', grad_input[0].size())\n",
    "    print('grad_input[1] size: ', grad_input[1].size())\n",
    "    print('grad_input[2] size: ', grad_input[2].size())\n",
    "    print('grad_output size: ', grad_output[0].size())\n",
    "    print('grad_input norm: ', grad_input[0].norm())\n",
    "    \n",
    "net.conv2.register_backward_hook(printgradnorm)\n",
    "\n",
    "out = net(input)\n",
    "err = loss_fn(out, target)\n",
    "err.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Recurrent Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, data_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        input_size = data_size + hidden_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, data, last_hidden):\n",
    "        input = torch.cat((data, last_hidden), 1)\n",
    "        hidden = self.i2h(input)\n",
    "        output = self.h2o(hidden)\n",
    "        return hidden, output\n",
    "    \n",
    "rnn = RNN(50, 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "batch_size = 10\n",
    "TIMESTEPS = 5\n",
    "\n",
    "batch = torch.randn(batch_size, 50)\n",
    "hidden = torch.zeros(batch_size, 20)\n",
    "target = torch.zeros(batch_size, 10)\n",
    "\n",
    "loss = 0\n",
    "for t in range(TIMESTEPS):\n",
    "    hidden, output = rnn(batch, hidden)\n",
    "    loss += loss_fn(output, target)\n",
    "    \n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7342)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-GPU examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DataParallelModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Linear(10, 20)\n",
    "        \n",
    "        self.block2 = nn.Linear(20, 20)\n",
    "        self.block2 = nn.DataParallel(self.block2)\n",
    "        \n",
    "        self.block3 = nn.Linear(20, 20)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.blcok3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of the model in CPU and part on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\n",
    "class DistributedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            embedding=nn.Embedding(1000, 10), \n",
    "            rnn=nn.Linear(10, 10).to(device))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.to(device)\n",
    "        x = self.rnn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cv3]",
   "language": "python",
   "name": "conda-env-cv3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
